{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_dotbracket_to_matrix(s):\n",
    "    m = np.zeros([len(s), len(s)])\n",
    "    for char_set in [['(', ')'], ['[', ']'], ['{', '}'], ['<', '>']]:\n",
    "        bp1 = []\n",
    "        bp2 = []\n",
    "        for i, char in enumerate(s):\n",
    "            if char == char_set[0]:\n",
    "                bp1.append(i)\n",
    "            if char == char_set[1]:\n",
    "                bp2.append(i)\n",
    "        for i in list(reversed(bp1)):\n",
    "            for j in bp2:\n",
    "                if j > i:\n",
    "                    m[i, j] = 1.0\n",
    "                    bp2.remove(j)\n",
    "                    break\n",
    "    return m + m.T\n",
    "\n",
    "\n",
    "def convert_matrix_to_dotbracket(m):\n",
    "    bp_list = convert_matrix_to_bp_list(m)\n",
    "    return convert_bp_list_to_dotbracket(bp_list, len(m))\n",
    "\n",
    "\n",
    "def convert_matrix_to_bp_list(m):\n",
    "    bp_list = []  # convert adjacency matrix to adjacency list\n",
    "    for i, row in enumerate(m):\n",
    "        for j, is_bp in enumerate(row[i + 1:]):\n",
    "            if is_bp:\n",
    "                bp_list.append((i, i + 1 + j))\n",
    "    return bp_list\n",
    "\n",
    "\n",
    "def convert_bp_list_to_dotbracket(bp_list,seq_len):\n",
    "    dotbracket = \".\"*seq_len\n",
    "    # group into bps that are not intertwined and can use same brackets!\n",
    "    groups = group_into_non_conflicting_bp_(bp_list)\n",
    "\n",
    "    # all bp that are not intertwined get (), but all others are\n",
    "    # groups to be nonconflicting and then asigned (), [], {}, <> by group\n",
    "    chars_set = [(\"(\", \")\"), (\"(\", \")\"), (\"[\", \"]\"), (\"{\", \"}\"), (\"<\", \">\")]\n",
    "    if len(groups) > len(chars_set):\n",
    "        print(f\"WARNING: PK too complex with {len(groups)} groups, not enough brackets to represent it.\")\n",
    "\n",
    "    for group,chars in zip(groups,chars_set):\n",
    "        for bp in group:\n",
    "            dotbracket = dotbracket[:bp[0]] + chars[0] + dotbracket[bp[0]+1:bp[1]] + chars[1] + dotbracket[bp[1]+1:]\n",
    "    return dotbracket\n",
    "\n",
    "\n",
    "def load_matrix_or_dbn(s):\n",
    "    num_lines = sum(1 for line in open(s))\n",
    "\n",
    "    if num_lines > 2:  # heuristic here\n",
    "        struct = np.loadtxt(s)  # load as base pair matrix\n",
    "        assert struct.shape[0] == struct.shape[1]\n",
    "    else:\n",
    "        try:  # load as dot-bracket string\n",
    "\n",
    "            dbn_struct = open(s, 'r').read().rstrip()\n",
    "\n",
    "            struct = convert_dotbracket_to_matrix(dbn_struct)\n",
    "        except:\n",
    "            raise ValueError('Unable to parse structure %s' % s)\n",
    "    return struct\n",
    "\n",
    "\n",
    "def group_into_non_conflicting_bp_(bp_list):\n",
    "    ''' given a conflict list from get_list_bp_conflicts_, group basepairs into groups that do not conflict\n",
    "\n",
    "    Args\n",
    "        conflict_list: list of pairs of base_pairs that are intertwined basepairs\n",
    "\n",
    "    Returns:\n",
    "        groups of baspairs that are not intertwined\n",
    "    '''\n",
    "    conflict_list = get_list_bp_conflicts_(bp_list)\n",
    "\n",
    "    non_redudant_bp_list = get_non_redudant_bp_list_(conflict_list)\n",
    "    bp_with_no_conflict = [bp for bp in bp_list if bp not in non_redudant_bp_list]\n",
    "    groups = [bp_with_no_conflict]\n",
    "    while non_redudant_bp_list != []:\n",
    "        current_bp = non_redudant_bp_list[0]\n",
    "        current_bp_conflicts = []\n",
    "        for conflict in conflict_list:\n",
    "            if current_bp == conflict[0]:\n",
    "                current_bp_conflicts.append(conflict[1])\n",
    "            elif current_bp == conflict[1]:\n",
    "                current_bp_conflicts.append(conflict[0])\n",
    "        group = [bp for bp in non_redudant_bp_list if bp not in current_bp_conflicts]\n",
    "        groups.append(group)\n",
    "        non_redudant_bp_list = current_bp_conflicts\n",
    "        conflict_list = [conflict for conflict in conflict_list if\n",
    "                         conflict[0] not in group and conflict[1] not in group]\n",
    "    return groups\n",
    "\n",
    "\n",
    "def get_list_bp_conflicts_(bp_list):\n",
    "    '''given a bp_list gives the list of conflicts bp-s which indicate PK structure\n",
    "    Args:\n",
    "        bp_list: of list of base pairs where the base pairs are list of indeces of the bp in increasing order (bp[0]<bp[1])\n",
    "    returns:\n",
    "        List of conflicting basepairs, where conflicting is pairs of base pairs that are intertwined.\n",
    "    '''\n",
    "    if len(bp_list) <= 1:\n",
    "        return []\n",
    "    else:\n",
    "        current_bp = bp_list[0]\n",
    "        conflicts = []\n",
    "        for bp in bp_list[1:]:\n",
    "            if (bp[0] < current_bp[1] and current_bp[1] < bp[1]):\n",
    "                conflicts.append([current_bp, bp])\n",
    "        return conflicts + get_list_bp_conflicts_(bp_list[1:])\n",
    "\n",
    "\n",
    "def get_non_redudant_bp_list_(conflict_list):\n",
    "    ''' given a conflict list get the list of nonredundant basepairs this list has\n",
    "\n",
    "    Args:\n",
    "        conflict_list: list of pairs of base_pairs that are intertwined basepairs\n",
    "    returns:\n",
    "        list of basepairs in conflict list without repeats\n",
    "    '''\n",
    "    non_redudant_bp_list = []\n",
    "    for conflict in conflict_list:\n",
    "        if conflict[0] not in non_redudant_bp_list:\n",
    "            non_redudant_bp_list.append(conflict[0])\n",
    "        if conflict[1] not in non_redudant_bp_list:\n",
    "            non_redudant_bp_list.append(conflict[1])\n",
    "    return non_redudant_bp_list\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def adjacency_matrix_to_bpseq(adj_matrix):\n",
    "    L = len(adj_matrix)\n",
    "    bpseq = [-1] * L  # 初始化bpseq列表，假设所有位置最初都没有配对\n",
    "\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if adj_matrix[i][j] == 1:\n",
    "                bpseq[i] = j\n",
    "                break  # 当找到配对时，跳出内层循环\n",
    "\n",
    "    return bpseq\n",
    "\n",
    "def compute_expected_accuracy(etp, efp, efn):\n",
    "    sen = ppv = f = 0.\n",
    "    if etp + efn != 0:\n",
    "        sen = etp / (etp + efn)\n",
    "    else:\n",
    "        sen = 0.\n",
    "        \n",
    "    if etp + efp != 0:\n",
    "        ppv = etp / (etp + efp)\n",
    "    else:\n",
    "        ppv = 0.\n",
    "        \n",
    "    if sen + ppv != 0:\n",
    "        f = 2 * sen * ppv / (sen + ppv)\n",
    "    else:\n",
    "        f = 0.\n",
    "\n",
    "    return (sen, ppv, f)\n",
    "\n",
    "def compute_expected_accuracy_pk(pred, label):\n",
    "    \n",
    "    # L = len(label)\n",
    "    # L2 = L * (L - 1) // 2\n",
    "    N = 0\n",
    "    pk_flag = False\n",
    "    \n",
    "    sump = 0.0\n",
    "    etp = 0.0\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        j = label[i]\n",
    "        if i < j:\n",
    "            for k in range(i + 1, j):\n",
    "                l = label[k]\n",
    "                lp = pred[k]\n",
    "                if j < lp:\n",
    "                    N += 1 # TP+FP\n",
    "                if j < l:\n",
    "                    sump += 1 # TP+FN\n",
    "                    if pred[i] == j and pred[k] == l:\n",
    "                        etp += 1 # TP\n",
    "    \n",
    "    efp = N - etp\n",
    "    efn = sump - etp\n",
    "    \n",
    "    if sump > 0:\n",
    "        pk_flag = True\n",
    "\n",
    "    return compute_expected_accuracy(etp, efn, efp), pk_flag\n",
    "\n",
    "\n",
    "\n",
    "def apc(x):\n",
    "    \"Perform average product correct, used for contact prediction.\"\n",
    "    a1 = x.sum(-1, keepdims=True)\n",
    "    a2 = x.sum(-2, keepdims=True)\n",
    "    a12 = x.sum((-1, -2), keepdims=True)\n",
    "\n",
    "    avg = a1 * a2\n",
    "    avg.div_(a12)  # in-place to reduce memory\n",
    "    normalized = x - avg\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bpRNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxi/mambaforge-pypy3/envs/torch/lib/python3.10/site-packages/torch/utils/_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
      "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n",
      "/home/wangxi/mambaforge-pypy3/envs/torch/lib/python3.10/site-packages/danling/runner/runner_state.py:164: RuntimeWarning: Unable to get git hash from CWD, fallback to git has of top-level code environment.\n",
      "  self.experiment_id = get_git_hash() or defaults.DEFAULT_EXPERIMENT_ID\n",
      "/home/wangxi/develop/deepprotein/deepprotein/data/dataset.py:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400410390/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  return torch.tensor(vals).squeeze(1).int()\n",
      "100%|██████████| 2914/2914 [00:25<00:00, 115.04it/s]\n"
     ]
    }
   ],
   "source": [
    "ckpt_fm = \"/home/wangxi/data_workspace/pseudoknots/log/rnafm-bpRNA-TR0-Auto-_home_wangxi_develop_rnafm_transformers_RNA-FM_pretrained-fusion-null-c226a2e9-6b2f86/C3B5X2fZt/checkpoints/epoch-13.pth\"\n",
    "ckpt_unirna = \"/home/wangxi/data_workspace/pseudoknots/log/new-model-bpRNA-TR0-Auto-_home_wangxi_develop_unirna_light_unirna_unirna_L16_E1024_DPRNA500M_STEP400K-fusion-null-a943f3b4-dbb1bd/C2LWU25Sc/checkpoints/epoch-24.pth\"\n",
    "data_list = \"/home/wangxi/data_workspace/pseudoknots/bpRNA-PK-TS0-1K.pkl\"\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "from deepprotein.runners.inferencer import LazyInferencer\n",
    "\n",
    "if not os.path.exists(\"result_unirna_bpRNA.pkl\"):\n",
    "    infer = LazyInferencer(ckpt_unirna, batch_size=1, sequence_pretrained=\"/home/wangxi/develop/unirna_light/weights/unirna_L16_E1024_DPRNA500M_STEP400K\")\n",
    "    result_unirna = infer.run(data_list)\n",
    "    with open(\"result_unirna_bpRNA.pkl\", \"wb+\") as f:\n",
    "        pickle.dump(result_unirna, f)\n",
    "else:\n",
    "    with open(\"result_unirna_bpRNA.pkl\", \"rb\") as f:\n",
    "        result_unirna = pickle.load(f)\n",
    "        \n",
    "if not os.path.exists(\"result_fm_bpRNA.pkl\"):\n",
    "    infer = LazyInferencer(ckpt_fm, batch_size=1)\n",
    "    result_fm = infer.run(data_list)\n",
    "    with open(\"result_fm_bpRNA.pkl\", \"wb+\") as f:\n",
    "        pickle.dump(result_fm, f)\n",
    "else:\n",
    "    with open(\"result_fm_bpRNA.pkl\", \"rb\") as f:\n",
    "        result_fm = pickle.load(f)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_label = pickle.load(open(data_list, \"rb\"))\n",
    "\n",
    "all_pred_unirna = []\n",
    "unirna_score = []\n",
    "unirna_score_cb = []\n",
    "unirna_score_pk = []\n",
    "\n",
    "all_pred_fm = []\n",
    "fm_score = []\n",
    "fm_score_cb = []\n",
    "fm_score_pk = []\n",
    "\n",
    "\n",
    "all_label = []\n",
    "\n",
    "methods_pred = []\n",
    "methods_score = []\n",
    "methods_score_pk = []\n",
    "methods_score_pk_cb = []\n",
    "\n",
    "unirna_pk_index = []\n",
    "\n",
    "unirna_length_list = []\n",
    "unirna_length_list_pk = []\n",
    "\n",
    "for i in range(len(data_label)):\n",
    "    id = data_label[i]['id']\n",
    "    label = data_label[i]['label']\n",
    "    all_label.extend(label.reshape(-1).tolist())\n",
    "    unirna_length_list.append(len(data_label[i]['seq']))\n",
    "    pred = np.array(result_unirna[\"label\"][i])\n",
    "    all_pred_unirna.extend(pred.reshape(-1).tolist())\n",
    "    pred = np.where(pred > 0.5, 1, 0)\n",
    "    f1 = f1_score(label.reshape(-1), pred.reshape(-1))\n",
    "    \n",
    "    unirna_score.append(f1)\n",
    "    pk_metrics = compute_expected_accuracy_pk(adjacency_matrix_to_bpseq(pred), adjacency_matrix_to_bpseq(label))\n",
    "                                              \n",
    "    if pk_metrics[-1]:\n",
    "        unirna_length_list_pk.append(len(data_label[i]['seq']))\n",
    "        unirna_score_pk.append(f1)\n",
    "        unirna_score_cb.append(pk_metrics[0][-1])\n",
    "        unirna_pk_index.append(i)\n",
    "\n",
    "    pred_fm = np.array(result_fm[\"label\"][i])\n",
    "    pred_fm = np.where(pred_fm > 0.5, 1, 0)\n",
    "    f1 = f1_score(label.reshape(-1), pred_fm.reshape(-1))\n",
    "    fm_score.append(f1)\n",
    "    pk_metrics = compute_expected_accuracy_pk(adjacency_matrix_to_bpseq(pred_fm), adjacency_matrix_to_bpseq(label))\n",
    "    \n",
    "    if pk_metrics[-1]:\n",
    "        fm_score_pk.append(f1)\n",
    "        fm_score_cb.append(pk_metrics[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPknot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = \"/home/siduanmiao/ipknot_run/ipknot_wx_test/sorted_file/bpRNA-PK-TS0_sorted.pkl\"\n",
    "pred_ipknot = \"/home/siduanmiao/ipknot_run/ipknot_wx_test/sorted_file/bpRNA-PK-TS0_predict_sorted.pkl\"\n",
    "\n",
    "data_label = pickle.load(open(data_list, \"rb\"))\n",
    "pred_all = pickle.load(open(pred_ipknot, \"rb\"))\n",
    "\n",
    "score = []\n",
    "score_pk = []\n",
    "score_cb = []\n",
    "length_list = []\n",
    "length_list_pk = []\n",
    "\n",
    "for i in range(len(data_label)):\n",
    "    id = data_label[i]['id']\n",
    "    label = data_label[i]['label']\n",
    "    pred = pred_all[i][\"label\"]\n",
    "    length_list.append(len(data_label[i]['seq']))\n",
    "    pred = np.where(pred > 0.5, 1, 0)\n",
    "    f1 = f1_score(label.reshape(-1), pred.reshape(-1))\n",
    "    \n",
    "    score.append(f1)\n",
    "    pk_metrics = compute_expected_accuracy_pk(adjacency_matrix_to_bpseq(pred), adjacency_matrix_to_bpseq(label))\n",
    "                                              \n",
    "    if pk_metrics[-1]:\n",
    "        length_list_pk.append(len(data_label[i]['seq']))\n",
    "        score_pk.append(f1)\n",
    "        score_cb.append(pk_metrics[0][-1])\n",
    "        \n",
    "with open(\"result_ipknot_bpRNA.pkl\", \"wb+\") as f:\n",
    "    pickle.dump({\n",
    "        \"score\": score,\n",
    "        \"score_pk\": score_pk,\n",
    "        \"score_cb\": score_cb,\n",
    "        \"length_list\": length_list,\n",
    "        \"length_list_pk\": length_list_pk\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result_ipknot_bpRNA.pkl\", \"rb\") as f:\n",
    "    result_ipknot = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_length(data, max_length=1000):\n",
    "    # 提取长度小于等于1000的点\n",
    "    filtered_score = [s for s, l in zip(data['score'], data['length_list']) if l <= max_length]\n",
    "    filtered_score_pk = [s for s, l in zip(data['score_pk'], data['length_list_pk']) if l <= max_length]\n",
    "    filtered_score_cb = [s for s, l in zip(data['score_cb'], data['length_list_pk']) if l <= max_length]\n",
    "\n",
    "    # 返回新的字典\n",
    "    return {\n",
    "        \"score\": filtered_score,\n",
    "        \"score_pk\": filtered_score_pk,\n",
    "        \"score_cb\": filtered_score_cb,\n",
    "        \"length_list\": [l for l in data['length_list'] if l <= max_length],\n",
    "        \"length_list_pk\": [l for l in data['length_list_pk'] if l <= max_length]\n",
    "    }\n",
    "\n",
    "filter_ipknot = filter_by_length(result_ipknot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/siduanmiao/benchmark/changeformatdata/\"\n",
    "benchmark_name = \"benchmark_8.pkl\"\n",
    "label_path = \"/mnt/siduanmiao/RNAstru_benchmark_ipknot/benchmark_8/test.pkl\"\n",
    "all_method = os.listdir(data_dir)\n",
    "methods_list = []\n",
    "\n",
    "for method in all_method:\n",
    "    if os.path.exists(os.path.join(data_dir, method, benchmark_name)):\n",
    "        methods_list.append(method)\n",
    "        \n",
    "methods_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle \n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_label = pickle.load(open(label_path, \"rb\"))\n",
    "\n",
    "methods_pred = []\n",
    "methods_score = []\n",
    "methods_score_pk = []\n",
    "methods_score_pk_cb = []\n",
    "\n",
    "length_list = []\n",
    "length_list_pk = []\n",
    "\n",
    "for method in methods_list:\n",
    "    with open(os.path.join(data_dir, method, benchmark_name), \"rb\") as f:\n",
    "        pred_all = pickle.load(f)\n",
    "        \n",
    "    print(f\"processing {method}\")\n",
    "    single_method_score = []\n",
    "    single_method_score_pk = []\n",
    "    single_method_score_cb = []\n",
    "    \n",
    "    for i in range(len(data_label)):\n",
    "        id = data_label[i]['id']\n",
    "        label = data_label[i]['label']\n",
    "        length_list.append(len(data_label[i]['seq']))\n",
    "        pred = np.array(pred_all[i][\"label\"])\n",
    "        pred = np.where(pred > 0.5, 1, 0)\n",
    "        \n",
    "        f1 = f1_score(label.reshape(-1), pred.reshape(-1))\n",
    "        \n",
    "        single_method_score.append(f1)\n",
    "        pk_metrics = compute_expected_accuracy_pk(adjacency_matrix_to_bpseq(pred), adjacency_matrix_to_bpseq(label))\n",
    "                                                \n",
    "        if pk_metrics[-1]:\n",
    "            length_list_pk.append(len(data_label[i]['seq']))\n",
    "            single_method_score_pk.append(f1)\n",
    "            single_method_score_cb.append(pk_metrics[0][-1])\n",
    "            \n",
    "    methods_score.append(single_method_score)\n",
    "    methods_score_pk.append(single_method_score_pk)\n",
    "    methods_score_pk_cb.append(single_method_score_cb)\n",
    "    \n",
    "with open(\"data-for-bpRNA.pkl\", \"wb+\") as f:\n",
    "    pickle.dump({\n",
    "        \"methods_list\": methods_list,\n",
    "        \"methods_score\": methods_score,\n",
    "        \"methods_score_pk\": methods_score_pk,\n",
    "        \"methods_score_pk_cb\": methods_score_pk_cb,\n",
    "        \"length_list\": length_list,\n",
    "        \"length_list_pk\": length_list_pk\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data-for-bpRNA.pkl\", \"rb\") as f:\n",
    "    methods_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict_by_length(data, max_length=1000):\n",
    "    # 提取长度小于等于1000的点\n",
    "    methods_score_filter = []\n",
    "    methods_score_pk_filter = []\n",
    "    methods_score_pk_cb_filter = []\n",
    "    methods_list = data[\"methods_list\"]\n",
    "    for index in range(len(methods_list)):\n",
    "        single_method_score = []\n",
    "        single_method_score_pk = []\n",
    "        single_method_score_pk_cb = []\n",
    "        \n",
    "        single_method_score = [s for s, l in zip(data[\"methods_score\"][index], data[\"length_list\"]) if l <= max_length]\n",
    "        single_method_score_pk = [s for s, l in zip(data[\"methods_score_pk\"][index], data[\"length_list_pk\"]) if l <= max_length]\n",
    "        single_method_score_pk_cb = [s for s, l in zip(data[\"methods_score_pk_cb\"][index], data[\"length_list_pk\"]) if l <= max_length]\n",
    "        \n",
    "        \n",
    "        methods_score_filter.append(single_method_score)\n",
    "        methods_score_pk_filter.append(single_method_score_pk)\n",
    "        methods_score_pk_cb_filter.append(single_method_score_pk_cb)\n",
    "        \n",
    "    # 返回新的字典\n",
    "    return {\n",
    "        \"methods_list\": data[\"methods_list\"],\n",
    "        \"methods_score\": methods_score_filter,\n",
    "        \"methods_score_pk\": methods_score_pk_filter,\n",
    "        \"methods_score_pk_cb\": methods_score_pk_cb_filter,\n",
    "        \"length_list\": [l for l in data['length_list'] if l <= max_length],\n",
    "        \"length_list_pk\": [l for l in data['length_list_pk'] if l <= max_length]\n",
    "    }\n",
    "\n",
    "methods_result_filter = filter_dict_by_length(methods_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "        \"UniRNA\": \"#D95F02\",\n",
    "        \"mxfold2\": \"#C06FA9\",\n",
    "        \"RNA-FM\": \"#B78FB2\",\n",
    "        \"mxfold\": \"#97B3C5\",\n",
    "        \"linearFold\": \"#B1A471\",\n",
    "        \"RNAfold\": \"#70A56E\",\n",
    "        \"RNAstructure\": \"#E5ADA8\",\n",
    "        \"ProbKnot\": \"#E96692\",\n",
    "        \"contrafold\": \"#E4B488\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ipknot\n",
    "df = pd.DataFrame({\"length\": result_ipknot[\"length_list\"], \"f1\": result_ipknot[\"score\"]})\n",
    "df_pk = pd.DataFrame({\"length\": result_ipknot[\"length_list_pk\"], \"f1\": result_ipknot[\"score_pk\"]})\n",
    "df_cb = pd.DataFrame({\"length\": result_ipknot[\"length_list_pk\"], \"f1\": result_ipknot[\"score_cb\"]})\n",
    "\n",
    "# 根据“length”列划分为三组\n",
    "def group_by_df(df):\n",
    "    bins = [0, 150, 500, 1500]\n",
    "    labels = ['<=150', '151-500', '500-1500']\n",
    "    df['length_group'] = pd.cut(df['length'], bins=bins, labels=labels)\n",
    "\n",
    "    # 计算每组“f1”列的平均值\n",
    "    grouped_df = df.groupby('length_group')['f1'].mean()\n",
    "    return grouped_df\n",
    "\n",
    "# Uni-RNA\n",
    "df = pd.DataFrame({\"length\": length_list, \"f1\": unirna_score})\n",
    "df_pk = pd.DataFrame({\"length\": length_list_pk, \"f1\": unirna_score_pk})\n",
    "df_cb = pd.DataFrame({\"length\": length_list_pk, \"f1\": unirna_score_cb})\n",
    "\n",
    "# 根据“length”列划分为三组\n",
    "def group_by_df(df):\n",
    "    bins = [0, 150, 500, 1000]\n",
    "    labels = ['<=150', '151-500', '>500']\n",
    "    df['length_group'] = pd.cut(df['length'], bins=bins, labels=labels)\n",
    "\n",
    "    # 计算每组“f1”列的平均值\n",
    "    grouped_df = df.groupby('length_group')['f1'].mean()\n",
    "    return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2914"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unirna_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uni-RNA:  0.6437240421502223 0.5299536279544587 0.27277472472767167\n",
      "RNA-FM:  0.557692691257335 0.4093522664761831 0.22080616411663256\n",
      "ipknot 0.5181428947763839 0.4504619597344123 0.05438228276374786\n",
      "ProbKnot 0.4899316384006009 0.42580240467625496 0.0210065269189357\n",
      "mxfold 0.5183789697411939 0.4723626099453287 0.0\n",
      "RNAstructure 0.4866155359567672 0.40278444067066416 0.0\n",
      "SPOTRNA 0.582678901620983 0.4852052571285208 0.13525588484395434\n",
      "linearFold 0.49596426509693303 0.3974546280853714 0.0\n",
      "RNAfold 0.4910309607991334 0.40404207837945516 0.0\n",
      "contrafold 0.4789496909254144 0.3933388544445596 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Uni-RNA: \", np.mean(unirna_score), np.mean(unirna_score_pk), np.mean(unirna_score_cb))\n",
    "print(\"RNA-FM: \", np.mean(fm_score), np.mean(fm_score_pk), np.mean(fm_score_cb))\n",
    "print(\"ipknot\", np.mean(filter_ipknot[\"score\"]), np.mean(filter_ipknot[\"score_pk\"]), np.mean(filter_ipknot[\"score_cb\"]))\n",
    "\n",
    "for i in range(len(methods_result_filter[\"methods_list\"])):\n",
    "    print(methods_result_filter[\"methods_list\"][i], np.mean(methods_result_filter[\"methods_score\"][i]), np.mean(methods_result_filter[\"methods_score_pk\"][i]), np.mean(methods_result_filter[\"methods_score_pk_cb\"][i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
